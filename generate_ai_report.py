import pandas as pd
import os
from dotenv import load_dotenv
import google.generativeai as genai
from duckduckgo_search import DDGS
from datetime import datetime
import argparse
from db_config import get_db_connection
import re

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

if not GOOGLE_API_KEY:
    print("WARNING: GOOGLE_API_KEY not found in .env file.")

# Gemini ì„¤ì •
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)

def search_news(keyword, num_results=5):
    """
    DuckDuckGoë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ê²€ìƒ‰
    """
    try:
        ddgs = DDGS()
        results = list(ddgs.news(keywords=f"{keyword} ì£¼ê°€ ì „ë§", region="kr-kr", safesearch="off", max_results=num_results))
        news_summary = ""
        for i, res in enumerate(results):
            news_summary += f"{i+1}. Title: {res['title']}\n   Source: {res['source']}\n   Date: {res['date']}\n   Snippet: {res['body']}\n\n"
        return news_summary
    except Exception as e:
        print(f"Error searching news for {keyword}: {e}")
        return "No news found."

def analyze_stock_with_gemini(stock_info, news_text):
    """
    Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ì¢…ëª© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± (í•„í„°ë§ ë°ì´í„° ê¸°ë°˜)
    """
    if not GOOGLE_API_KEY:
        return "API Key missing. Cannot perform AI analysis."

    # gemini-2.5-flash ì‚¬ìš© (ìµœì‹  ì•ˆì • ë²„ì „)
    model = genai.GenerativeModel('gemini-2.5-flash')

    prompt = f"""
    ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ë² í…Œë‘ ì£¼ì‹ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ ì œê³µëœ ë°ì´í„°ì™€ ë‰´ìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ ì¢…ëª©ì— ëŒ€í•œ íˆ¬ì ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

    ## ë¶„ì„ ëŒ€ìƒ ì¢…ëª©
    - ì¢…ëª©ëª…: {stock_info['name']} ({stock_info['ticker']})
    - í˜„ì¬ê°€: {stock_info['close']:,}ì›
    - ê±°ë˜ëŒ€ê¸ˆ: {stock_info['trading_value']/100000000:.1f}ì–µì›
    - 5ì¼ ë“±ë½ë¥ : {stock_info['change_5d']:.2f}%
    - ê±°ë˜ëŸ‰ ì¦ê°€ìœ¨: {stock_info['vol_ratio']:.2f}ë°°
    - ì¢…í•© ì ìˆ˜: {stock_info['final_score']:.1f}ì  (ê±°ë˜ëŒ€ê¸ˆ 40% + ëª¨ë©˜í…€ 30% + ê±°ë˜ëŸ‰ 30%)

    ## ìµœê·¼ ê´€ë ¨ ë‰´ìŠ¤
    {news_text}

    ## ì‘ì„± ê°€ì´ë“œ
    1. **ìš”ì•½ ì˜ê²¬**: ë§¤ìˆ˜/ê´€ì‹¬ì¢…ëª©/ë³´ë¥˜ ì¤‘ í•˜ë‚˜ì˜ ì˜ê²¬ì„ ì œì‹œí•˜ê³  ì´ìœ ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.
    2. **ëª¨ë©˜í…€ ë¶„ì„**: 5ì¼ ë“±ë½ë¥ ê³¼ ê±°ë˜ëŸ‰ ì¦ê°€ìœ¨ì„ ë°”íƒ•ìœ¼ë¡œ í˜„ì¬ ëª¨ë©˜í…€ ìƒíƒœë¥¼ ë¶„ì„í•˜ì„¸ìš”.
    3. **ìœ ë™ì„± ë¶„ì„**: ê±°ë˜ëŒ€ê¸ˆì„ ë°”íƒ•ìœ¼ë¡œ ì¢…ëª©ì˜ ìœ ë™ì„±ê³¼ ì•ˆì •ì„±ì„ í‰ê°€í•˜ì„¸ìš”.
    4. **ì¬ë£Œ ë¶„ì„**: ë‰´ìŠ¤ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í˜¸ì¬/ì•…ì¬ë¥¼ ë¶„ì„í•˜ì„¸ìš”.
    5. **ë¦¬ìŠ¤í¬ ìš”ì¸**: ì£¼ì˜í•´ì•¼ í•  ì ì„ ì§€ì í•˜ì„¸ìš”.
    6. **íˆ¬ì ì „ëµ**: ì§„ì… íƒ€ì´ë°, ëª©í‘œ ìˆ˜ìµë¥ , ì†ì ˆ ê¸°ì¤€ì„ ì œì•ˆí•˜ì„¸ìš”.

    ë³´ê³ ì„œëŠ” ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ê°„ê²°í•˜ê³  ì‹¤ìš©ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    """

    import time
    max_retries = 3
    retry_delay = 10  # ì´ˆ

    for attempt in range(max_retries):
        try:
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            error_msg = str(e)
            if "429" in error_msg or "quota" in error_msg.lower():
                if attempt < max_retries - 1:
                    print(f"    âš ï¸ API í• ë‹¹ëŸ‰ ì´ˆê³¼. {retry_delay}ì´ˆ í›„ ì¬ì‹œë„... ({attempt + 1}/{max_retries})")
                    time.sleep(retry_delay)
                    retry_delay *= 2  # ì§€ìˆ˜ ë°±ì˜¤í”„
                    continue
                else:
                    return f"âš ï¸ API í• ë‹¹ëŸ‰ ì´ˆê³¼ë¡œ ë¶„ì„ ì‹¤íŒ¨. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n\n[ìƒì„¸ ì—ëŸ¬: {error_msg[:200]}]"
            else:
                return f"âš ï¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error_msg[:200]}"

    return "âš ï¸ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼"

def parse_ai_response(analysis_text):
    """
    AI ë¶„ì„ ê²°ê³¼ì—ì„œ êµ¬ì¡°í™”ëœ ì •ë³´ ì¶”ì¶œ
    """
    # ê¸°ë³¸ê°’
    result = {
        'summary': '',
        'recommendation': 'WATCH_MORE',
        'confidence_score': 50.0,
        'momentum_analysis': '',
        'liquidity_analysis': '',
        'risk_factors': ''
    }

    # ìš”ì•½ ì˜ê²¬ì—ì„œ recommendation ì¶”ì¶œ
    if 'ë§¤ìˆ˜' in analysis_text or 'BUY' in analysis_text.upper():
        result['recommendation'] = 'STRONG_APPROVE'
        result['confidence_score'] = 70.0
    elif 'ê´€ì‹¬ì¢…ëª©' in analysis_text or 'WATCH' in analysis_text.upper():
        result['recommendation'] = 'WATCH_MORE'
        result['confidence_score'] = 50.0
    elif 'ë³´ë¥˜' in analysis_text or 'HOLD' in analysis_text.upper() or 'ë§¤ë„' in analysis_text:
        result['recommendation'] = 'DO_NOT_APPROVE'
        result['confidence_score'] = 30.0

    # ì„¹ì…˜ë³„ ë‚´ìš© ì¶”ì¶œ
    sections = {
        'ìš”ì•½ ì˜ê²¬': 'summary',
        'ëª¨ë©˜í…€ ë¶„ì„': 'momentum_analysis',
        'ìœ ë™ì„± ë¶„ì„': 'liquidity_analysis',
        'ë¦¬ìŠ¤í¬ ìš”ì¸': 'risk_factors'
    }

    for section_name, field_name in sections.items():
        pattern = f'[*#]*{section_name}[*#]*[:\\s]*(.*?)(?=[*#]*(?:ëª¨ë©˜í…€ ë¶„ì„|ìœ ë™ì„± ë¶„ì„|ì¬ë£Œ ë¶„ì„|ë¦¬ìŠ¤í¬ ìš”ì¸|íˆ¬ì ì „ëµ)|$)'
        match = re.search(pattern, analysis_text, re.DOTALL | re.IGNORECASE)
        if match:
            content = match.group(1).strip()
            # ë¶ˆí•„ìš”í•œ ë§ˆí¬ë‹¤ìš´ ì œê±°
            content = re.sub(r'[*#]+', '', content).strip()
            result[field_name] = content[:500]  # ê¸¸ì´ ì œí•œ

    # summaryê°€ ë¹„ì–´ìˆìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ì˜ ì²« 200ì ì‚¬ìš©
    if not result['summary']:
        result['summary'] = analysis_text[:200].strip()

    return result

def save_to_database(ticker, analysis_data):
    """
    AI ë¶„ì„ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
    """
    try:
        with get_db_connection() as conn:
            cur = conn.cursor()
            cur.execute("""
                INSERT INTO ai_analysis_reports
                (ticker, report_date, summary, recommendation, confidence_score,
                 momentum_analysis, liquidity_analysis, risk_factors)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (ticker, report_date) DO UPDATE SET
                    summary = EXCLUDED.summary,
                    recommendation = EXCLUDED.recommendation,
                    confidence_score = EXCLUDED.confidence_score,
                    momentum_analysis = EXCLUDED.momentum_analysis,
                    liquidity_analysis = EXCLUDED.liquidity_analysis,
                    risk_factors = EXCLUDED.risk_factors,
                    created_at = CURRENT_TIMESTAMP
            """, (
                ticker,
                datetime.now().date(),
                analysis_data['summary'],
                analysis_data['recommendation'],
                analysis_data['confidence_score'],
                analysis_data['momentum_analysis'],
                analysis_data['liquidity_analysis'],
                analysis_data['risk_factors']
            ))
        return True
    except Exception as e:
        print(f"    âš ï¸ DB ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def run_investigation(input_csv="filtered_stocks.csv", top_n=5, use_db_priority=True):
    """
    AI ë¶„ì„ ì‹¤í–‰

    Args:
        input_csv: CSV íŒŒì¼ ê²½ë¡œ (DB ìš°ì„ ìˆœìœ„ ì‚¬ìš© ì‹œ ë¬´ì‹œë¨)
        top_n: ë¶„ì„í•  ì¢…ëª© ìˆ˜
        use_db_priority: Trueë©´ DBì—ì„œ ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì„ ì •
    """

    if use_db_priority:
        # DB ê¸°ë°˜ ìš°ì„ ìˆœìœ„ ì„ ì • (ì¶”ì²œ ë°©ì‹)
        print("ğŸ“Š DB ê¸°ë°˜ ìš°ì„ ìˆœìœ„ ì„ ì • ì¤‘...")
        print("   - status='monitoring' ì¢…ëª© ì¤‘")
        print("   - ì˜¤ëŠ˜ AI ë¶„ì„ ì•ˆ ëœ ì¢…ëª©")
        print("   - final_score ìˆœìœ¼ë¡œ ì„ ì •\n")

        from db_config import get_db_connection
        import pandas as pd

        with get_db_connection() as conn:
            df = pd.read_sql(f"""
                SELECT ticker, name, close, trading_value, change_5d, vol_ratio, final_score
                FROM stock_pool
                WHERE status = 'monitoring'
                  AND ticker NOT IN (
                    SELECT DISTINCT ticker
                    FROM ai_analysis_reports
                    WHERE report_date = CURRENT_DATE
                  )
                ORDER BY final_score DESC
                LIMIT {top_n}
            """, conn)

        if df.empty:
            print("âš ï¸  ëª¨ë“  monitoring ì¢…ëª©ì´ ì´ë¯¸ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print("    ë˜ëŠ” stock_poolì— monitoring ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False

        print(f"âœ… {len(df)}ê°œ ì¢…ëª© ì„ ì • ì™„ë£Œ\n")
        top_stocks = df

    else:
        # ê¸°ì¡´ CSV ê¸°ë°˜ ë°©ì‹
        if not os.path.exists(input_csv):
            print(f"{input_csv} not found.")
            return False

        df = pd.read_csv(input_csv)
        if df.empty:
            print("No filtered stocks found.")
            return False

        # ìƒìœ„ ì¢…ëª© ì„ ì • (final_score ê¸°ì¤€)
        df = df.sort_values('final_score', ascending=False)
        top_stocks = df.head(top_n)

    report_filename = f"ai_analysis_report_{datetime.now().strftime('%Y%m%d')}.md"

    print(f"Generating AI analysis report for top {top_n} stocks...")

    import time
    successful_count = 0
    failed_count = 0

    with open(report_filename, "w", encoding="utf-8") as f:
        f.write(f"# StockGravity AI Analysis Report\n")
        f.write(f"**ìƒì„±ì¼**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(f"**ë¶„ì„ ëŒ€ìƒ**: í•„í„°ë§ëœ ìƒìœ„ {top_n}ê°œ ì¢…ëª©\n\n")
        f.write("---\n\n")

        for idx, (_, row) in enumerate(top_stocks.iterrows(), 1):
            print(f"  [{idx}/{len(top_stocks)}] {row['name']} ({row['ticker']}) ë¶„ì„ ì¤‘...")

            # ë‰´ìŠ¤ ê²€ìƒ‰
            news = search_news(row['name'])

            # AI ë¶„ì„
            analysis = analyze_stock_with_gemini(row, news)

            # ë¦¬í¬íŠ¸ ì‘ì„±
            f.write(f"## {row['name']} ({row['ticker']})\n\n")
            f.write(f"**ì¢…í•© ì ìˆ˜**: {row['final_score']:.1f}ì  | ")
            f.write(f"**í˜„ì¬ê°€**: {row['close']:,}ì› | ")
            f.write(f"**ê±°ë˜ëŒ€ê¸ˆ**: {row['trading_value']/100000000:.1f}ì–µì›\n\n")
            f.write(analysis)
            f.write("\n\n---\n\n")

            # ì„±ê³µ/ì‹¤íŒ¨ ì¹´ìš´íŠ¸
            if "âš ï¸" in analysis or "Error" in analysis:
                failed_count += 1
            else:
                successful_count += 1
                # DBì— ì €ì¥ (ì„±ê³µí•œ ê²½ìš°ì—ë§Œ)
                ticker = str(row['ticker']).zfill(6)
                analysis_data = parse_ai_response(analysis)
                if save_to_database(ticker, analysis_data):
                    print(f"    âœ… DB ì €ì¥ ì™„ë£Œ")
                else:
                    print(f"    âš ï¸ DB ì €ì¥ ì‹¤íŒ¨ (íŒŒì¼ì€ ì €ì¥ë¨)")

            # Rate limit ë°©ì§€: ì¢…ëª© ê°„ ëŒ€ê¸° (ë§ˆì§€ë§‰ ì¢…ëª©ì€ ì œì™¸)
            if idx < len(top_stocks):
                print(f"    ë‹¤ìŒ ì¢…ëª© ë¶„ì„ ëŒ€ê¸° ì¤‘ (3ì´ˆ)...")
                time.sleep(3)

    print(f"\nâœ… AI Analysis Report saved to {report_filename}")
    print(f"   ì„±ê³µ: {successful_count}ê°œ | ì‹¤íŒ¨: {failed_count}ê°œ")

    if failed_count > 0:
        print(f"\nâš ï¸  ì¼ë¶€ ì¢…ëª© ë¶„ì„ ì‹¤íŒ¨. API í• ë‹¹ëŸ‰ì„ í™•ì¸í•˜ê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")

    return True

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Generate AI analysis report for filtered stocks')
    parser.add_argument('--top', type=int, default=20, help='Number of top stocks to analyze (default: 20)')
    parser.add_argument('--use-csv', action='store_true', help='Use CSV instead of DB priority (legacy mode)')
    args = parser.parse_args()

    # ê¸°ë³¸ì€ DB ìš°ì„ ìˆœìœ„ ëª¨ë“œ
    use_db = not args.use_csv

    success = run_investigation(top_n=args.top, use_db_priority=use_db)
    if not success:
        exit(1)
