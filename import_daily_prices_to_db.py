#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
daily_prices.csvë¥¼ DBë¡œ ì¼ê´„ ì„í¬íŠ¸ (ìµœì´ˆ 1íšŒ)
"""
import pandas as pd
from db_config import get_db_connection
from datetime import datetime
import sys

def import_csv_to_db(csv_file='daily_prices.csv', batch_size=10000):
    """CSV íŒŒì¼ì„ DBë¡œ ì¼ê´„ ì„í¬íŠ¸"""
    print(f"\n{'='*60}")
    print(f"ğŸ“¥ {csv_file} â†’ PostgreSQL ì„í¬íŠ¸ ì‹œì‘")
    print(f"{'='*60}\n")

    # CSV ë¡œë“œ
    print("1ï¸âƒ£ CSV íŒŒì¼ ë¡œë”©...")
    try:
        df = pd.read_csv(csv_file, dtype={'ticker': str})
        print(f"   âœ… {len(df):,}í–‰ ë¡œë“œ ì™„ë£Œ")
    except FileNotFoundError:
        print(f"   âŒ {csv_file} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return False

    # ë°ì´í„° ì „ì²˜ë¦¬
    print("\n2ï¸âƒ£ ë°ì´í„° ì „ì²˜ë¦¬...")
    df['ticker'] = df['ticker'].astype(str).str.zfill(6)
    df['date'] = pd.to_datetime(df['date'])

    # ì¤‘ë³µ ì œê±° (ticker, date ê¸°ì¤€)
    before_count = len(df)
    df = df.drop_duplicates(subset=['ticker', 'date'], keep='last')
    after_count = len(df)
    if before_count != after_count:
        print(f"   âš ï¸ ì¤‘ë³µ ì œê±°: {before_count:,} â†’ {after_count:,}í–‰")

    # ì •ë ¬
    df = df.sort_values(['ticker', 'date'])
    print(f"   âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {len(df):,}í–‰")
    print(f"   ğŸ“… ë‚ ì§œ ë²”ìœ„: {df['date'].min()} ~ {df['date'].max()}")
    print(f"   ğŸ“Š ì¢…ëª© ìˆ˜: {df['ticker'].nunique():,}ê°œ")

    # DB ì €ì¥
    print(f"\n3ï¸âƒ£ DB ì €ì¥ ì¤‘ (ë°°ì¹˜ í¬ê¸°: {batch_size:,})...")

    total_saved = 0
    total_updated = 0
    total_batches = (len(df) + batch_size - 1) // batch_size

    with get_db_connection() as conn:
        cur = conn.cursor()

        for i in range(0, len(df), batch_size):
            batch = df.iloc[i:i+batch_size]
            batch_num = i // batch_size + 1

            for _, row in batch.iterrows():
                try:
                    cur.execute("""
                        INSERT INTO daily_prices
                        (ticker, date, open, high, low, close, volume, diff)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                        ON CONFLICT (ticker, date) DO UPDATE SET
                            open = EXCLUDED.open,
                            high = EXCLUDED.high,
                            low = EXCLUDED.low,
                            close = EXCLUDED.close,
                            volume = EXCLUDED.volume,
                            diff = EXCLUDED.diff,
                            created_at = CURRENT_TIMESTAMP
                    """, (
                        row['ticker'],
                        row['date'].date(),
                        float(row['open']) if pd.notna(row['open']) else None,
                        float(row['high']) if pd.notna(row['high']) else None,
                        float(row['low']) if pd.notna(row['low']) else None,
                        float(row['close']) if pd.notna(row['close']) else None,
                        int(row['volume']) if pd.notna(row['volume']) else None,
                        str(row['diff']) if pd.notna(row['diff']) else None
                    ))

                    if cur.rowcount == 1:
                        total_saved += 1
                    else:
                        total_updated += 1

                except Exception as e:
                    print(f"   âš ï¸ {row['ticker']} {row['date'].date()} ì €ì¥ ì‹¤íŒ¨: {e}")
                    continue

            # ì§„í–‰ ìƒí™© ì¶œë ¥
            progress = (batch_num / total_batches) * 100
            print(f"   ì§„í–‰: {batch_num}/{total_batches} ë°°ì¹˜ ({progress:.1f}%) | "
                  f"ì €ì¥: {total_saved:,} | ì—…ë°ì´íŠ¸: {total_updated:,}", end='\r')

        print()  # ì¤„ë°”ê¿ˆ
        conn.commit()

    print(f"\n{'='*60}")
    print(f"âœ… ì„í¬íŠ¸ ì™„ë£Œ!")
    print(f"{'='*60}")
    print(f"   ğŸ“ ì‹ ê·œ ì €ì¥: {total_saved:,}í–‰")
    print(f"   ğŸ”„ ì—…ë°ì´íŠ¸: {total_updated:,}í–‰")
    print(f"   ğŸ“Š ì´ ì²˜ë¦¬: {total_saved + total_updated:,}í–‰")

    # DB í†µê³„ í™•ì¸
    with get_db_connection() as conn:
        cur = conn.cursor()
        cur.execute("""
            SELECT
                COUNT(*) as total_rows,
                COUNT(DISTINCT ticker) as total_tickers,
                MIN(date) as min_date,
                MAX(date) as max_date
            FROM daily_prices
        """)
        stats = cur.fetchone()

        print(f"\nğŸ“Š DB ìµœì¢… í†µê³„:")
        print(f"   - ì´ ë°ì´í„°: {stats[0]:,}í–‰")
        print(f"   - ì¢…ëª© ìˆ˜: {stats[1]:,}ê°œ")
        print(f"   - ê¸°ê°„: {stats[2]} ~ {stats[3]}")

    return True


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='Import daily_prices.csv to PostgreSQL')
    parser.add_argument('--csv', default='daily_prices.csv', help='CSV file path')
    parser.add_argument('--batch', type=int, default=10000, help='Batch size')
    args = parser.parse_args()

    start_time = datetime.now()
    success = import_csv_to_db(args.csv, args.batch)

    if success:
        elapsed = (datetime.now() - start_time).total_seconds()
        print(f"\nâ±ï¸  ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ")
    else:
        sys.exit(1)
